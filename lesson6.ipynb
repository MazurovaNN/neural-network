{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3EGEjmGSNbZDj8/sUos+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MazurovaNN/neural-network/blob/main/lesson6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "n_RnJX1W9BZb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "data_r = zipfile.ZipFile('train.zip', 'r')\n",
        "data_r.extractall()"
      ],
      "metadata": {
        "id": "FWeOWeQu9P6P"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_r = zipfile.ZipFile('test.zip', 'r')\n",
        "data_r.extractall()"
      ],
      "metadata": {
        "id": "zyPFY66-9iBU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(path):\n",
        "  data = []\n",
        "  for path_image in sorted(os.listdir(path=path)):\n",
        "    image = Image.open(path + path_image) #Открываем изображение.\n",
        "    data.append(np.array(image)) #Загружаем пиксели.\n",
        "  return data"
      ],
      "metadata": {
        "id": "IkBXjuQf9qr1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = download_data(r\"train/images/\")\n",
        "Y_train = download_data(r\"train/masks/\")\n",
        "X_test = download_data(r\"test/images/\")\n",
        "Y_test = download_data(r\"test/masks/\")\n"
      ],
      "metadata": {
        "id": "5_Uaav-K9ycV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(input_image, input_mask):\n",
        "   input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "   input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "   return input_image, input_mask"
      ],
      "metadata": {
        "id": "rWn1Ptqp93XL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = resize(X_train, Y_train)"
      ],
      "metadata": {
        "id": "po6_M39-99Md"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3QGQNOg-LIZ",
        "outputId": "e94cbea9-3b43-4ecb-9dfc-8b03371b2ad0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 128, 3), dtype=int32, numpy=\n",
              "array([[[238, 241, 246],\n",
              "        [185, 190, 196],\n",
              "        [249, 255, 255],\n",
              "        ...,\n",
              "        [178, 177, 185],\n",
              "        [220, 219, 225],\n",
              "        [235, 237, 250]],\n",
              "\n",
              "       [[254, 255, 255],\n",
              "        [252, 255, 255],\n",
              "        [250, 251, 253],\n",
              "        ...,\n",
              "        [213, 209, 223],\n",
              "        [199, 192, 199],\n",
              "        [152, 145, 152]],\n",
              "\n",
              "       [[194, 194, 196],\n",
              "        [239, 238, 243],\n",
              "        [253, 254, 255],\n",
              "        ...,\n",
              "        [ 96,  88, 101],\n",
              "        [157, 142, 149],\n",
              "        [148, 132, 133]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[213, 207, 217],\n",
              "        [238, 233, 239],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [247, 240, 234],\n",
              "        [218, 211, 203],\n",
              "        [241, 234, 224]],\n",
              "\n",
              "       [[231, 225, 235],\n",
              "        [166, 161, 167],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [255, 253, 250],\n",
              "        [237, 230, 222],\n",
              "        [223, 216, 208]],\n",
              "\n",
              "       [[246, 240, 250],\n",
              "        [198, 191, 198],\n",
              "        [199, 197, 208],\n",
              "        ...,\n",
              "        [240, 237, 230],\n",
              "        [249, 238, 232],\n",
              "        [255, 253, 243]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ8cKzlm-Sv_",
        "outputId": "9be98910-80c5-433b-93c2-6286dbd9d3f1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_eM5hqW-ahF",
        "outputId": "c3ac7a99-543d-4564-c2e2-a94c3dd79de3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqGPlnP-gIA",
        "outputId": "71918032-7f23-4f3a-836d-10dc45461a55"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5u3QzT--k6y",
        "outputId": "11bb2557-ec13-4f3c-e06b-841ea6bf8b36"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([132,  41, 246, 255], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_train[0][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJrNsCoX-qMI",
        "outputId": "509b9bdf-742c-4e8e-8b18-1b3bc9e88487"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palette = {0 : (60, 16, 152), # Building\n",
        "           1 : (132, 41, 246), # Land\n",
        "           2 : (110, 193, 228), # Road\n",
        "           3 : (254, 221, 58), # Vegetation\n",
        "           4 : (226, 169, 41), # Water\n",
        "           5 : (155, 155, 155)} # Unlabeled"
      ],
      "metadata": {
        "id": "WDrEw3Y--xqo"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invert_palette = {v: k for k, v in palette.items()}"
      ],
      "metadata": {
        "id": "NzbVIbeQ-2wf"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сегментация нейронной сети в RGB изображение\n",
        "def convert_to_color(arr_2d, palette=palette):\n",
        "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d"
      ],
      "metadata": {
        "id": "LSpBsGNH-8GK"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8) # принадлежность каждого пикселя классу\n",
        "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # расстояние до ближайшего класса для пикселей\n",
        "    for c, i in palette.items():\n",
        "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2) # ищем расстояние для каждого пикселя до проверяемого класса по евклиду рас-ие\n",
        "      condition = min_distance > distance # поиск элементов меньше min_distance\n",
        "      min_distance[condition] = distance[condition] # замена дистанции найденных элементов\n",
        "      arr_2d[condition] = i # замена класса найденных элементов\n",
        "\n",
        "    for c, i in palette.items():\n",
        "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "      arr_2d[m] = i\n",
        "\n",
        "    arr_2d = arr_2d.tolist()\n",
        "    for i in range(len(arr_2d)):\n",
        "      for j in range(len(arr_2d[0])):\n",
        "        label = [0, 0, 0, 0, 0, 0]\n",
        "        label[arr_2d[i][j]] = 1\n",
        "        arr_2d[i][j] = label\n",
        "    arr_2d = np.array(arr_2d)\n",
        "\n",
        "    return arr_2d"
      ],
      "metadata": {
        "id": "Vc1GHwCV_Evl"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pred = np.array(X_train).reshape([7, 128, 128, 3])/255\n",
        "X_test_pred = np.array(X_test).reshape([2, 128, 128, 3])/255\n",
        "Y_train_pred = []\n",
        "for i in range(len(Y_train)):\n",
        "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
        "Y_train_pred = np.array(Y_train_pred)\n",
        "Y_test_pred = []\n",
        "for i in range(len(Y_test)):\n",
        "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
        "Y_test_pred = np.array(Y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "qSwOVqc6_T1f",
        "outputId": "54ab290b-7d23-4054-dc5f-6209a7960384"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 3075744 into shape (2,128,128,3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-3b2897c6ea8f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mY_train_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_from_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3075744 into shape (2,128,128,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import *\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ],
      "metadata": {
        "id": "15zgjsIF_dCP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   return x"
      ],
      "metadata": {
        "id": "So0aeHw9_l1v"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   return x"
      ],
      "metadata": {
        "id": "YLuTSqlT_rQ0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "   return f, p"
      ],
      "metadata": {
        "id": "6zdr1Zhf_w1x"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_model():\n",
        "   # inputs\n",
        "   inputs = layers.Input(shape=(128,128,3))\n",
        "   # encoder: contracting path - downsample\n",
        "   # 1 - downsample\n",
        "   f1, p1 = downsample_block(inputs, 64)\n",
        "   # 2 - downsample\n",
        "   f2, p2 = downsample_block(p1, 128)\n",
        "   # 3 - downsample\n",
        "   f3, p3 = downsample_block(p2, 256)\n",
        "   # 4 - downsample\n",
        "   f4, p4 = downsample_block(p3, 512)\n",
        "   # 5 - bottleneck\n",
        "   bottleneck = double_conv_block(p4, 1024)\n",
        "   # decoder: expanding path - upsample\n",
        "   # 6 - upsample\n",
        "   u6 = upsample_block(bottleneck, f4, 512)\n",
        "   # 7 - upsample\n",
        "   u7 = upsample_block(u6, f3, 256)\n",
        "   # 8 - upsample\n",
        "   u8 = upsample_block(u7, f2, 128)\n",
        "   # 9 - upsample\n",
        "   u9 = upsample_block(u8, f1, 64)\n",
        "   # outputs\n",
        "   outputs = layers.Conv2D(6, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "   # unet model with Keras Functional API\n",
        "   unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "   return unet_model"
      ],
      "metadata": {
        "id": "UfQX2cRc_3JP"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model = build_unet_model()"
      ],
      "metadata": {
        "id": "WgzV0-oNABIu"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "xJblBY_N_3MP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = unet_model.fit(X_train_pred, Y_train_pred,  epochs=10, validation_data = (X_test_pred, Y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "8vGLMTzvANty",
        "outputId": "cb8895d3-0ee9-4505-e52e-f4b00e3c2d22"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def unet_model(image_size, output_classes):\n",
        "\n",
        "#     #Входной слой\n",
        "#     input_layer = Input(shape=image_size + (3,))\n",
        "#     conv_1 = Conv2D(64, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2, padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(input_layer)\n",
        "#     #Сворачиваем\n",
        "#     conv_1_1 = Conv2D(128, 4,\n",
        "#                                       activation=LeakyReLU(),\n",
        "#                                       strides=2,\n",
        "#                                       padding='same',\n",
        "#                                       kernel_initializer='glorot_normal',\n",
        "#                                       use_bias=False)(conv_1)\n",
        "#     batch_norm_1 = BatchNormalization()(conv_1_1)\n",
        "\n",
        "#     #2\n",
        "#     conv_2 = Conv2D(256, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2,\n",
        "#                                     padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(batch_norm_1)\n",
        "#     batch_norm_2 = BatchNormalization()(conv_2)\n",
        "\n",
        "#     #3\n",
        "#     conv_3 = Conv2D(512, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2,\n",
        "#                                     padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(batch_norm_2)\n",
        "#     batch_norm_3 = BatchNormalization()(conv_3)\n",
        "\n",
        "#     #4\n",
        "#     conv_4 = Conv2D(512, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2,\n",
        "#                                     padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(batch_norm_3)\n",
        "#     batch_norm_4 = BatchNormalization()(conv_4)\n",
        "\n",
        "#     #5\n",
        "#     conv_5 = Conv2D(512, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2,\n",
        "#                                     padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(batch_norm_4)\n",
        "#     batch_norm_5 = BatchNormalization()(conv_5)\n",
        "\n",
        "#     #6\n",
        "#     conv_6 = Conv2D(512, 4,\n",
        "#                                     activation=LeakyReLU(),\n",
        "#                                     strides=2,\n",
        "#                                     padding='same',\n",
        "#                                     kernel_initializer='glorot_normal',\n",
        "#                                     use_bias=False)(batch_norm_5)\n",
        "#     ch, cw = get_crop_shape(conv_5,conv_5)\n",
        "#       #Разворачиваем\n",
        "#     #1\n",
        "#     up_1 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(conv_6), conv_5])\n",
        "#     batch_up_1 = BatchNormalization()(up_1)\n",
        "\n",
        "#     #Добавим Dropout от переобучения\n",
        "#     batch_up_1 = Dropout(0.25)(batch_up_1)\n",
        "\n",
        "#     #2\n",
        "#     up_2 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(batch_up_1), conv_4])\n",
        "#     batch_up_2 = BatchNormalization()(up_2)\n",
        "#     batch_up_2 = Dropout(0.25)(batch_up_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     #3\n",
        "#     up_3 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(batch_up_2), conv_3])\n",
        "#     batch_up_3 = BatchNormalization()(up_3)\n",
        "#     batch_up_3 = Dropout(0.25)(batch_up_3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     #4\n",
        "#     up_4 = Concatenate()([Conv2DTranspose(256, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(batch_up_3), conv_2])\n",
        "#     batch_up_4 = BatchNormalization()(up_4)\n",
        "\n",
        "\n",
        "#     #5\n",
        "#     up_5 = Concatenate()([Conv2DTranspose(128, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(batch_up_4), conv_1_1])\n",
        "#     batch_up_5 = BatchNormalization()(up_5)\n",
        "\n",
        "\n",
        "#     #6\n",
        "#     up_6 = Concatenate()([Conv2DTranspose(64, 4, activation='relu', strides=2,\n",
        "#                                                                           padding='same',\n",
        "#                                                                           kernel_initializer='glorot_normal',\n",
        "#                                                                           use_bias=False)(batch_up_5), conv_1])\n",
        "#     batch_up_6 = BatchNormalization()(up_6)\n",
        "\n",
        "\n",
        "#     #Выходной слой\n",
        "#     output_layer = Conv2DTranspose(output_classes, 4, activation='sigmoid', strides=2,\n",
        "#                                                    padding='same',\n",
        "#                                                    kernel_initializer='glorot_normal')(batch_up_6)\n",
        "\n",
        "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "DRh8PXx5AjHs"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import *"
      ],
      "metadata": {
        "id": "4sLFYQtIAtOB"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Ba2qSxAJAybw"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model((796,644), 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bFx3NWopA4MC",
        "outputId": "87598d44-da96-4f0c-dbba-f66ab3baa987"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-92be1c04bf46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m796\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m644\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция для подсчёта DICE коэффициента\n",
        "def dice_coef(y_pred, y_true):\n",
        "    y_pred = tf.unstack(y_pred, axis=3)\n",
        "    y_true = tf.unstack(y_true, axis=3)\n",
        "    dice_summ = 0\n",
        "\n",
        "    for i, (a_y_pred, b_y_true) in enumerate(zip(y_pred, y_true)):\n",
        "        dice_calculate = (2 * tf.math.reduce_sum(a_y_pred * b_y_true) + 1) /\\\n",
        "         (tf.math.reduce_sum(a_y_pred + b_y_true) + 1)\n",
        "\n",
        "        dice_summ += dice_calculate\n",
        "    avg_dice = dice_summ/CLASSES\n",
        "    return avg_dice"
      ],
      "metadata": {
        "id": "aoGgu2AIA8tW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция для подсчета DICE loss\n",
        "def dice_loss(y_pred, y_true):\n",
        "    d_loss = 1 - dice_coef(y_pred, y_true)\n",
        "    return d_loss"
      ],
      "metadata": {
        "id": "5L79DOT4BKvO"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary crossentropy + 0.25 * DICE\n",
        "def dice_bce_loss(y_pred, y_true):\n",
        "    total_loss = 0.25 * dice_loss(y_pred, y_true) + keras.losses.binary_crossentropy(y_pred, y_true)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "KIE6bfa9BMpy"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}